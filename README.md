# Federated Learning with Differential Privacy: Experimental Code

This repository contains code for experimenting with Federated Learning (FL) incorporating Differential Privacy (DP) on the MNIST digits dataset. The experiments aim to investigate the impact of IID and non-IID datasets on the performance of FL with DP, as well as to explore the privacy-convergence tradeoff.

## Usage:

1. **Dataset Preparation**: Ensure MNIST dataset is available and preprocessed into IID and non-IID formats.

2. **Configuration**: Adjust parameters such as protection levels, number of clients, and optimization strategies in the configuration file.

3. **Experiment Execution**: Run the main script to conduct experiments on the chosen dataset and configurations.

4. **Analysis**: Analyze experimental results to understand the impact of IID vs. non-IID datasets and the privacy-convergence tradeoff.
